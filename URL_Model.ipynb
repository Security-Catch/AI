{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Gbe8XZuj_VYy0nxMk5KwexpFjsAX8LYP","authorship_tag":"ABX9TyPhZdR8JRvVing+umTmf16b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Google Drive 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YruEJfd4okx9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715825338075,"user_tz":-540,"elapsed":21501,"user":{"displayName":"Ryujin","userId":"11057201220526475886"}},"outputId":"9bbdb59d-239b-4b0d-f9c9-d64ef7c5d359"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihHm4I1Ik6-O","executionInfo":{"status":"ok","timestamp":1715825345451,"user_tz":-540,"elapsed":3278,"user":{"displayName":"Ryujin","userId":"11057201220526475886"}},"outputId":"4fdac999-ba4a-44dd-f949-8850c2e05926"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import pandas as pd\n","from urllib.parse import urlparse\n","from nltk.tokenize import word_tokenize\n","import re\n","from sklearn.feature_extraction.text import CountVectorizer\n","import pickle\n","from scipy.sparse import save_npz, load_npz\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.ensemble import RandomForestClassifier"],"metadata":{"id":"e4UM_QxVArQG","executionInfo":{"status":"ok","timestamp":1715825348699,"user_tz":-540,"elapsed":305,"user":{"displayName":"Ryujin","userId":"11057201220526475886"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKRlUBcBez3F","executionInfo":{"status":"ok","timestamp":1715825566680,"user_tz":-540,"elapsed":15913,"user":{"displayName":"Ryujin","userId":"11057201220526475886"}},"outputId":"100b321e-21e9-46c5-e66d-119e6e4ca532"},"outputs":[{"output_type":"stream","name":"stdout","text":["중복 제거 후의 전체 샘플 수: 47640\n"]}],"source":["\n","\n","# URL 전처리 함수\n","def preprocess_url(url):\n","    # URL 파싱\n","    parsed_url = urlparse(url)\n","    protocol = parsed_url.scheme\n","    domain = parsed_url.netloc\n","    path = parsed_url.path\n","    parameters = parsed_url.params\n","    fragment = parsed_url.fragment\n","\n","    # 토큰화\n","    tokenized_protocol = word_tokenize(protocol)\n","    tokenized_domain = word_tokenize(domain)\n","    tokenized_path = word_tokenize(path)\n","    tokenized_parameters = word_tokenize(parameters)\n","    tokenized_fragment = word_tokenize(fragment)\n","\n","    # 정규화\n","    normalized_domain = domain.lower()\n","    normalized_domain = re.sub(r'[^a-zA-Z]', '', normalized_domain)  # 특수 문자 및 숫자 제거\n","    if normalized_domain.startswith('www'):  # 접두사 \"www.\" 제거\n","        normalized_domain = normalized_domain[4:]\n","\n","    # 피처 추출\n","    domain_length = len(normalized_domain)\n","    protocol_type = protocol if protocol else \"Unknown\"\n","\n","    # 결과 반환\n","    return ' '.join(tokenized_protocol + tokenized_domain + tokenized_path +\n","                    tokenized_parameters + tokenized_fragment + [normalized_domain, str(domain_length), protocol_type])\n","\n","\n","# CSV 파일 읽기\n","data = pd.read_csv('/content/drive/MyDrive/URL_Data.csv')\n","\n","# 필요한 열 선택 및 중복 제거\n","data = data[['v1', 'v2']]\n","data['v1'] = data['v1'].replace(['ham', 'spam'], [0, 1])\n","data.drop_duplicates(subset=['v2'], inplace=True)\n","print('중복 제거 후의 전체 샘플 수:', len(data))\n","\n","# 전처리 수행\n","preprocessed_data = []\n","for url in data['v2']:\n","    preprocessed_url = preprocess_url(url)\n","    preprocessed_data.append(preprocessed_url)\n","\n","# 레이블 가져오기\n","labels = data['v1']\n","\n","# 단어 카운트 벡터 생성\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(preprocessed_data)\n","\n","# CountVectorizer 저장\n","with open('/content/drive/MyDrive/vectorizer.joblib', 'wb') as f:\n","    pickle.dump(vectorizer, f)\n","\n","# 전처리된 데이터와 레이블 저장\n","save_npz('/content/drive/MyDrive/X.npz', X)  # 희소 행렬을 .npz 형식으로 저장\n","np.save('/content/drive/MyDrive/labels.npy', labels.values)  # 레이블을 .npy 형식으로 저장\n","\n"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.ensemble import RandomForestClassifier\n","import joblib\n","from scipy.sparse import load_npz\n","\n","# 희소 행렬 데이터와 레이블 로드\n","X = load_npz('/content/drive/MyDrive/X.npz')\n","labels = np.load('/content/drive/MyDrive/labels.npy', allow_pickle=True)\n","\n","# 데이터를 학습 세트와 테스트 세트로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n","\n","# RandomForest 분류기 인스턴스화 및 모델 학습\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측 수행\n","predictions = rf_classifier.predict(X_test)\n","\n","# 모델 성능 평가\n","print(\"정확도:\", accuracy_score(y_test, predictions))\n","print(\"\\n분류 리포트:\\n\", classification_report(y_test, predictions))\n","\n","# 모델 저장\n","with open('/content/drive/MyDrive/rf_classifier.joblib', 'wb') as f:\n","    pickle.dump(rf_classifier, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCtPHUc1kw3J","executionInfo":{"status":"ok","timestamp":1715826024028,"user_tz":-540,"elapsed":445770,"user":{"displayName":"Ryujin","userId":"11057201220526475886"}},"outputId":"92a77d4c-fab5-4142-be30-7ad8a1ab9489"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["정확도: 0.9495172124265323\n","\n","분류 리포트:\n","               precision    recall  f1-score   support\n","\n","           0       0.91      0.99      0.95      4542\n","           1       0.99      0.91      0.95      4986\n","\n","    accuracy                           0.95      9528\n","   macro avg       0.95      0.95      0.95      9528\n","weighted avg       0.95      0.95      0.95      9528\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MuRbhP0u32Rl"},"execution_count":null,"outputs":[]}]}